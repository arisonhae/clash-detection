# clashdetection.py
# Streamlit ê¸°ë°˜ Clash ìš°ì„ ìˆœìœ„ + Gemini ê²°ê³¼ë³´ê³ ì„œ + ì±—ë´‡

import pandas as pd
import streamlit as st
import google.generativeai as genai

# ======================================
# 0. ê¸°ë³¸ ì„¤ì •
# ======================================

st.set_page_config(
    page_title="AI Clash Agent (CI Ranking)",
    page_icon="ğŸ§±",
    layout="wide"
)

st.title("ğŸ§± AI Clash Agent (CI Ranking + Gemini Report)")

st.markdown(
    """
ì—…ë¡œë“œí•œ Clash CSV/XLSXë¥¼ ê¸°ë°˜ìœ¼ë¡œ **ê°„ì„­ ì¤‘ìš”ë„(CI)**ë¥¼ ê³„ì‚°í•˜ê³ ,
- ìš°ì„  ìˆ˜ì •í•´ì•¼ í•  ê°„ì„­ ìˆœìœ„(Rank)ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.  
- Top 10 + íŒì •ë¶ˆê°€ í•­ëª©ì„ **Gemini ê²°ê³¼ë³´ê³ ì„œ**ë¡œ ìš”ì•½í•©ë‹ˆë‹¤.  
- ê²°ê³¼ ê´€ë ¨ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
)

st.markdown(
    """
### ğŸ” CI ê³„ì‚° ê³µì‹ ë° ì˜ë¯¸

ì´ ì›¹ì•±ì€ Bitaraf et al. (Buildings, 2024)ì˜ **ê°œì„ ëœ BIM ê¸°ë°˜ ê°„ì„­ ìš°ì„ ìˆœìœ„ ì‚°ì • ë°©ë²•**ì„ ì°¸ê³ í•˜ì—¬  
ì•„ë˜ì™€ ê°™ì€ CI(Clash Importance) ê³µì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

> CI = P Ã— WS Ã— WMEP Ã— N Ã— R Ã— U

- P : Clash ê²°ê³¼ì—ì„œ ê°€ì ¸ì˜¨ ê°„ì„­ ê¹Šì´(ì¹¨íˆ¬ëŸ‰)  
- WS : ê¸°ë‘¥, ë³´, ê¸°ì´ˆ, ì „ë‹¨ë²½, ìŠ¬ë˜ë¸Œ ë“± êµ¬ì¡° ìš”ì†Œ ê°€ì¤‘ì¹˜  
- WMEP : ë•íŠ¸, ì„¤ë¹„, ë°°ê´€, ì „ê¸°ì„¤ë¹„ ë“± MEP ìš”ì†Œ ê°€ì¤‘ì¹˜  
  - WS, WMEP ê°’ì˜ êµ¬ì¡°ëŠ” ë…¼ë¬¸ì—ì„œ ì œì‹œí•œ BWM(Bestâ€“Worst Method) ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì²´ê³„ë¥¼ ë”°ë¦…ë‹ˆë‹¤.
- N : ë™ì¼ MEP ìš”ì†Œê°€ ë°œìƒì‹œí‚¤ëŠ” ê°„ì„­ ê°œìˆ˜  
- R : ì¸µë³„ ê°„ì„­ ë°€ë„ ë¹„ìœ¨(í•´ë‹¹ ì¸µ ê°„ì„­ ìˆ˜ / ìµœë‹¤ ì¸µ ê°„ì„­ ìˆ˜)  
- U : ìš©ë„ ê³„ìˆ˜ (í˜„ì¬ëŠ” 1.0ìœ¼ë¡œ ê³ ì •)

ë…¼ë¬¸ì˜ ê¸°ë³¸ ê³µì‹ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë˜,  
N Â· R Â· U ì„¸ ë³€ìˆ˜ì˜ êµ¬ì²´ì ì¸ ì •ì˜ì™€ ê³„ì‚° ë°©ì‹ì€ ì´ ì›¹ì•±ì—ì„œ ì—…ë¡œë“œí•œ Clash í…Œì´ë¸”ë§Œìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆë„ë¡  
ë…ìì ìœ¼ë¡œ ë‹¨ìˆœí™”Â·ì¬êµ¬ì„±í•œ ë²„ì „ì´ë¼ëŠ” ì ì„ í•¨ê»˜ ì°¸ê³ í•´ ì£¼ì„¸ìš”.
"""
)

# ======================================
# 1. íƒ€ì… íŒë³„ í•¨ìˆ˜ (MEP / êµ¬ì¡°)
# ======================================

def detect_mep_type(s: str) -> str:
    t = str(s).lower()
    if "airterminal" in t:
        return "AirTerminal"
    if "ductsegment" in t or "duct segment" in t:
        return "DuctSegment"
    if "pipe" in t:
        return "PipeSegment"
    if "cabletray" in t or "cable_tray" in t:
        return "CableTray"
    return "OtherMEP"


def detect_struct_type(s: str) -> str:
    t = str(s).lower()
    if "column" in t or "ifccolumn" in t:
        return "Column"
    if "beam" in t or "ifcbeam" in t:
        return "Beam"
    if "slab" in t or "roof" in t or "ifcslab" in t:
        return "Slab"
    if "wall" in t or "ifcwall" in t:
        return "Wall"
    if "pile" in t or "ifcpile" in t:
        return "Pile"
    return "OtherStruct"

# ======================================
# 2. ê°€ì¤‘ì¹˜ í•¨ìˆ˜
# ======================================

def ws_from_struct(st_type: str) -> float:
    if st_type == "Column": return 0.321
    if st_type == "Beam": return 0.321
    if st_type == "Pile": return 0.188
    if st_type == "Wall": return 0.125
    if st_type == "Slab": return 0.045
    return 0.045


def w_mep_from_type(mep_type: str) -> float:
    if mep_type == "DuctSegment": return 0.54
    if mep_type == "AirTerminal": return 0.28
    if mep_type == "PipeSegment": return 0.12
    return 0.06

# ======================================
# 3. CI ê³„ì‚° í•¨ìˆ˜
# ======================================

def compute_ci(df: pd.DataFrame, u_use: float = 1.0, p_min_threshold: float = 0.0) -> pd.DataFrame:
    df = df.copy()

    col_clash_name = "ê°„ì„­ ì´ë¦„"
    col_distance = "ê±°ë¦¬"
    col_mep_id = "í•­ëª© ID 1"
    col_mep_floor = "ë„ë©´ì¸µ"
    col_mep_type_raw = "í•­ëª© ìœ í˜•1"
    col_st_id = "í•­ëª© ID 2"
    col_st_floor = "ë„ë©´ì¸µ.1"
    col_st_type_raw = "í•­ëª© ìœ í˜•2"

    required_cols = [
        col_clash_name, col_distance, col_mep_id, col_mep_floor,
        col_mep_type_raw, col_st_id, col_st_floor, col_st_type_raw
    ]

    for c in required_cols:
        if c not in df.columns:
            raise KeyError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {c}")

    df[col_distance] = pd.to_numeric(df[col_distance], errors="coerce").fillna(0.0)
    df["P"] = df[col_distance].abs()

    df["MEP_Type"] = df[col_mep_type_raw].fillna(df[col_mep_id]).apply(detect_mep_type)
    df["ST_Type"] = df[col_st_type_raw].fillna(df[col_st_id]).apply(detect_struct_type)

    df["WS"] = df["ST_Type"].apply(ws_from_struct)
    df["WMEP"] = df["MEP_Type"].apply(w_mep_from_type)

    df["N"] = df.groupby(col_mep_id)[col_clash_name].transform("count").astype(float)

    floor_counts = df.groupby(col_mep_floor)[col_clash_name].transform("count").astype(float)
    max_floor_count = floor_counts.max() if floor_counts.max() > 0 else 1.0
    df["R"] = floor_counts / max_floor_count

    df["U"] = float(u_use)

    df["CI_raw"] = df["P"] * df["WS"] * df["WMEP"] * df["N"] * df["R"] * df["U"]

    if p_min_threshold > 0:
        df["CI"] = df["CI_raw"]
        df.loc[df["P"] < p_min_threshold, "CI"] = 0.0
    else:
        df["CI"] = df["CI_raw"]

    df["íŒì •ê²°ê³¼"] = "íŒì •ê°€ëŠ¥"
    mask_unknown = (df["MEP_Type"] == "OtherMEP") | (df["ST_Type"] == "OtherStruct"]
    df.loc[mask_unknown, "íŒì •ê²°ê³¼"] = "íŒì •ë¶ˆê°€"

    df = df.sort_values("CI", ascending=False).reset_index(drop=True)
    df["CI_rank"] = df["CI"].rank(method="min", ascending=False).astype(int)

    return df

# ======================================
# Gemini ì„¤ì •
# ======================================

PREFERRED_MODELS = [
    "gemini-2.5-flash",
    "gemini-1.5-flash",
    "gemini-1.5-pro",
]

def init_gemini():
    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key:
        st.sidebar.error("âš ï¸ GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None

    st.sidebar.markdown(f"ğŸ”‘ Gemini key prefix: `{api_key[:6]}***`")
    st.sidebar.markdown(f"ğŸ“¦ google-generativeai ë²„ì „: `{genai.__version__}`")

    genai.configure(api_key=api_key)

    available_names = []
    try:
        models = list(genai.list_models())
        for m in models:
            methods = getattr(m, "supported_generation_methods", [])
            if "generateContent" in methods:
                available_names.append(m.name)
    except Exception:
        pass

    candidate_names = []
    if available_names:
        for pref in PREFERRED_MODELS:
            for an in available_names:
                if an.endswith(pref):
                    candidate_names.append(an.replace("models/", ""))
                    break

    if not candidate_names:
        candidate_names = PREFERRED_MODELS[:]

    last_error = None
    for name in candidate_names:
        try:
            model = genai.GenerativeModel(name)
            _ = model.generate_content("í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.")
            st.sidebar.success(f"âœ… Gemini ì—°ê²° ì„±ê³µ (ì‚¬ìš© ëª¨ë¸: `{name}`)")
            st.session_state["gemini_model_name"] = name
            return model
        except Exception as e:
            last_error = e

    st.sidebar.error(f"âŒ Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {last_error}")
    return None

# ======================================
# Gemini ê²°ê³¼ë³´ê³ ì„œ ìƒì„±
# ======================================

def generate_report_gemini(model, df_ci: pd.DataFrame) -> str:
    if df_ci is None or df_ci.empty:
        return "ë°ì´í„°ê°€ ì—†ì–´ ë³´ê³ ì„œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    top10 = df_ci.head(10).copy()
    cols = [
        "CI_rank", "ê°„ì„­ ì´ë¦„", "MEP í•­ëª© ID", "ST í•­ëª© ID",
        "MEP_Type", "ST_Type", "íŒì •ê²°ê³¼", "P", "WS", "WMEP", "N", "R", "CI"
    ]
    cols = [c for c in cols if c in top10.columns]
    top10_small = top10[cols]
    
    unknown_rows = df_ci[df_ci["íŒì •ê²°ê³¼"] == "íŒì •ë¶ˆê°€"][cols]

    top10_md = top10_small.to_markdown(index=False)
    unknown_md = unknown_rows.to_markdown(index=False) if not unknown_rows.empty else "ì—†ìŒ"

    prompt = f"""
ë„ˆëŠ” ê±´ì„¤/BIM ê°„ì„­ ê²€í† ë¥¼ ë•ëŠ” ì—”ì§€ë‹ˆì–´ì•¼.

[Top 10]
{top10_md}

[íŒì •ë¶ˆê°€]
{unknown_md}

Top 10 íŠ¹ì§• ìš”ì•½,
ìš°ì„  ì¡°ì¹˜ ëŒ€ìƒ 3~5ê°œ,
íŒì •ë¶ˆê°€ í•­ëª© ì•ˆë‚´ê¹Œì§€ í¬í•¨í•˜ì—¬ í•œê¸€ ë³´ê³ ì„œ ì‘ì„±
"""
    response = model.generate_content(prompt)
    return response.text

# ======================================
# Gemini ì±—ë´‡
# ======================================

def init_chat_state():
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []


def chat_with_gemini(model, user_msg: str, df_ci: pd.DataFrame | None):
    context = ""
    if df_ci is not None and not df_ci.empty:
        top5 = df_ci.head(5).copy()
        cols = ["CI_rank","ê°„ì„­ ì´ë¦„","MEP í•­ëª© ID","ST í•­ëª© ID","íŒì •ê²°ê³¼","CI"]
        cols = [c for c in cols if c in  top5.columns]
        context = top5[cols].to_markdown(index=False)

    history_text = ""
    for h in st.session_state["chat_history"][-6:]:
        role = "ì‚¬ìš©ì" if h["role"] == "user" else "AI"
        history_text += f"{role}: {h['content']}\n"

    prompt = f"""
[ìµœê·¼ ëŒ€í™”]
{history_text}

[Clash ìš°ì„ ìˆœìœ„ ìš”ì•½]
{context}

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_msg}
"""

    response = model.generate_content(prompt)
    return response.text

# ======================================
# UI
# ======================================

if "report_text" not in st.session_state:
    st.session_state["report_text"] = None

st.sidebar.header("ğŸ“‚ ì…ë ¥ ë°ì´í„° ì—…ë¡œë“œ")
uploaded_file = st.sidebar.file_uploader("Clash ê²°ê³¼ CSV/XLSX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv","xlsx"])

p_min_threshold = st.sidebar.number_input(
    "P ìµœì†Œ ê°„ì„­ ê¹Šì´ ê¸°ì¤€ (ì„ íƒ, 0ì´ë©´ ì‚¬ìš© ì•ˆ í•¨)",
    min_value=0.0, max_value=1000.0, value=0.0, step=1.0,
)

st.sidebar.markdown("---")
st.sidebar.markdown("ğŸ“Œ íŒŒì¼ í˜•ì‹ ì˜ˆì‹œ: `ê°„ì„­ ì´ë¦„, ê±°ë¦¬, í•­ëª© ID 1, ë„ë©´ì¸µ, í•­ëª© ìœ í˜•1...`")

df_ci = None

if uploaded_file is not None:
    st.subheader("ğŸ“ ì—…ë¡œë“œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")

    try:
        if uploaded_file.name.lower().endswith(".csv"):
            df_raw = pd.read_csv(uploaded_file, encoding="utf-8-sig")
        else:
            df_raw = pd.read_excel(uploaded_file)
    except Exception as e:
        st.error(f"íŒŒì¼ì„ ì½ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        df_raw = None

    if df_raw is not None:
        st.dataframe(df_raw.head(20), use_container_width=True)

        st.subheader("ğŸ§® CI ê³„ì‚° ë° Rank ì‚°ì¶œ")

        try:
            df_ci = compute_ci(df_raw, u_use=1.0, p_min_threshold=p_min_threshold)
            st.success("âœ… CI ê³„ì‚° ë° Rank ì‚°ì¶œ ì™„ë£Œ")

            st.session_state["report_text"] = None

            st.markdown("**ìƒìœ„ 20ê°œ ê°„ì„­ (CI ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)**")
            show_cols = [
                "CI_rank","ê°„ì„­ ì´ë¦„","MEP í•­ëª© ID","ST í•­ëª© ID","MEP_Type",
                "ST_Type","íŒì •ê²°ê³¼","P","WS","WMEP","N","R","CI",
            ]
            show_cols = [c for c in show_cols if c in df_ci.columns]
            st.dataframe(df_ci[show_cols].head(20), use_container_width=True)

            st.markdown("#### ğŸ“¥ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ")
            out_csv = df_ci.to_csv(index=False, encoding="utf-8-sig")

            st.download_button(
                label="ğŸ”½ CI ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
                data=out_csv,
                file_name="ci_result_with_rank.csv",
                mime="text/csv",
            )

        except Exception as e:
            st.error(f"CI ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

else:
    st.info("ì¢Œì¸¡ì—ì„œ CSV/XLSX íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ CI ê³„ì‚°ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

model = init_gemini()

st.markdown("---")
st.markdown("### ğŸ¤– Gemini ê²°ê³¼ë³´ê³ ì„œ")

if model is None:
    st.warning("Gemini ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    if df_ci is None or df_ci.empty:
        st.info("ë¨¼ì € CSV/XLSX ì—…ë¡œë“œ í›„ CI ê³„ì‚°ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        if st.session_state["report_text"] is None:
            with st.spinner("Geminiê°€ ê²°ê³¼ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."):
                st.session_state["report_text"] = generate_report_gemini(model, df_ci)

        st.markdown("#### ğŸ“„ ê²°ê³¼ë³´ê³ ì„œ (AI ìë™ ìƒì„±)")
        st.write(st.session_state["report_text"])

st.markdown("---")
st.subheader("ğŸ’¬ Gemini ì±—ë´‡")

init_chat_state()

if model is None:
    st.warning("Gemini ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
else:
    for h in st.session_state["chat_history"]:
        role = "user" if h["role"] == "user" else "assistant"
        with st.chat_message(role):
            st.markdown(h["content"])

    user_input = st.chat_input("CI, Rank, íŒì •ë¶ˆê°€ ì˜ë¯¸ë‚˜ ê²°ê³¼ í•´ì„ ë“±ì„ ë¬¼ì–´ë³´ì„¸ìš”.")
    if user_input:
        st.session_state["chat_history"].append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("AIê°€ ë‹µë³€ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤..."):
                answer = chat_with_gemini(model, user_input, df_ci)
                st.markdown(answer)

        st.session_state["chat_history"].append(
            {"role": "assistant", "content": answer}
        )
